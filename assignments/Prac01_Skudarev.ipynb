{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2GPoeVHUVTq"
   },
   "source": [
    "# Практическое задание 1\n",
    "\n",
    "## Данные о студенте\n",
    "\n",
    "1. **ФИО**: Скударев Егор Геннадьевич\n",
    "2. **Факультет**: механико-математический\n",
    "3. **Курс**: 4\n",
    "4. **Группа**: 411\n",
    "\n",
    "## Замечания\n",
    "\n",
    "* Название ноутбука с реализацией должно иметь шаблон \"**Prac01_Ivanov.ipynb**\" и посылаться на почту mlcoursemm@gmail.com с темой **[CV2021:Prac01]**\n",
    "* Дедлайн будет оговорен в чате курса\n",
    "* Соблюдаем кодекс чести (по нулям и списавшему, и давшему списать)\n",
    "* Можно (и нужно!) применять для реализации только библиотеку **Numpy**\n",
    "* Ничего, крому Numpy, нельзя использовать для реализации \n",
    "* **Keras** используется только для тестирования Вашей реализации\n",
    "* Если какой-то из классов не проходит приведенные тесты, то соответствующее задание не оценивается\n",
    "* Возможно использование дополнительных (приватных) тестов\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hT1dNA7Gb35a"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\skuda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Не найден указанный модуль.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m   \u001b[1;31m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: Не найден указанный модуль.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-633f50560324>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Нужно для тестирования\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# go/tf-wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 83\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\skuda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Не найден указанный модуль.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "# Вам понадобится для реализации\n",
    "import numpy as np\n",
    "# Нужно для тестирования\n",
    "from tensorflow import keras\n",
    "import keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.1-cp38-cp38-win_amd64.whl (370.7 MB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.15.6-py2.py3-none-any.whl (173 kB)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (50.3.1.post20201107)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.28.0-py2.py3-none-any.whl (136 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.3-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\skuda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.11)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=78da09d1b91711e2b03b6e680f83a9c7a2a3282ad210de2a3451620d775c04ca\n",
      "  Stored in directory: c:\\users\\skuda\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19558 sha256=b87ffa4b0f9a2b4a7232a88f5fec43c6c73d3a59601226f4680c93fd0e8cd1bc\n",
      "  Stored in directory: c:\\users\\skuda\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: gast, google-pasta, protobuf, tensorflow-estimator, termcolor, absl-py, flatbuffers, opt-einsum, astunparse, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, tensorboard-plugin-wit, oauthlib, requests-oauthlib, google-auth-oauthlib, grpcio, markdown, tensorboard, keras-preprocessing, wrapt, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 cachetools-4.2.1 flatbuffers-1.12 gast-0.3.3 google-auth-1.28.0 google-auth-oauthlib-0.4.3 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.15.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G7sQn2ZXh9Y"
   },
   "source": [
    "* Вспомогательные функции для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vXhfmihINmY"
   },
   "outputs": [],
   "source": [
    "def compare_tensors(x, y, tol=0.001, test_name='Test'):\n",
    "  assert (x.shape == y.shape), test_name + ' different shapes'\n",
    "  diff = np.sum((y - x)**2)\n",
    "  assert (diff < tol), test_name + ' Failed!'\n",
    "  print (test_name + ' Passed!')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pq_lVMUle_ii"
   },
   "outputs": [],
   "source": [
    "def compare_tensors_array(x, y, tol=0.001, test_name='Test'):\n",
    "  assert (len(x) == len(y)), test_name + ' different lengths'\n",
    "  for i in range(len(x)):\n",
    "    t = test_name + ' subtest ' + str(i)\n",
    "    compare_tensors(x[i], y[i], tol=tol, test_name=t)\n",
    "  print (test_name + ' Passed!')\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4iNYGlDyNAF"
   },
   "source": [
    "* Шаблон класса любой операции (слоя), которую Вам необходимо будет реализовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05lYhmjMSm0s"
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self):\n",
    "        self.name = 'Layer'       \n",
    "    def forward(self, input_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caE-Xn1ZY79p"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9yuQiPjyOBZ"
   },
   "source": [
    "* (1 балл) Реализация \"спрямляющего\" слоя Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJIqDFDC-8Gh"
   },
   "outputs": [],
   "source": [
    "class FlattenLayer(Layer):\n",
    "    def __init__(self):\n",
    "      self.name = 'Flatten'\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Преобразуем в двухмерный тензор: при этом по первой размерности НЕ преобразуем\n",
    "      # Выкладываем данные: сначала по последней размерности, затем по предпоследней и т.д.\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAD92fJkYcNI"
   },
   "source": [
    "* Функция предварительного тестирования слоя **Flatten**\n",
    "* Функции с названием \"**test_**\" не менять\n",
    "* Вы можете самостоятельно поиграться с параметрами типа B/C/H/W etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZsoCXd1HioL"
   },
   "outputs": [],
   "source": [
    "def test_FlattenLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Flatten(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = FlattenLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Flatten 1')\n",
    "  B = 1\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Flatten(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = FlattenLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Flatten 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMe7eba6Yu4a"
   },
   "source": [
    "* Запуск теста слоя Flatten\n",
    "* Нужно, чтобы все тесты были '*Passed!*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pST9EihGKTEh"
   },
   "outputs": [],
   "source": [
    "test_FlattenLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOngWlbqyQJ9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6NfaNFKZGOk"
   },
   "source": [
    "* (1 балл) Реализация слоя субдискретизации **Global Average Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1d3U8gE1-8J1"
   },
   "outputs": [],
   "source": [
    "class GAP2DLayer(Layer):\n",
    "    def __init__(self):\n",
    "      self.name = 'GAP2D'\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Сворачиваем по двум последним размерностям (то есть на выходе - минус две размерности)\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9KLCdrTLT-j"
   },
   "outputs": [],
   "source": [
    "def test_GAP2DLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.GlobalAveragePooling2D(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = GAP2DLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test GAP2D 1')\n",
    "  B = 1\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.GlobalAveragePooling2D(data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = GAP2DLayer().forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test GAP2D 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbuDxhloPLKs"
   },
   "outputs": [],
   "source": [
    "test_GAP2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbse3gb2ySI_"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2CCmuiZZTXp"
   },
   "source": [
    "* (2 балла) Реализация слоя субдискретизации **MaxPooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFSW6Xpp-8NS"
   },
   "outputs": [],
   "source": [
    "class MaxPool2DLayer(Layer):\n",
    "    def __init__(self, pool_size=2, stride=2):\n",
    "      self.name = 'MaxPool2D'\n",
    "      self.pool_size = pool_size\n",
    "      self.stride = stride\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kvCIn_aXUPkD"
   },
   "outputs": [],
   "source": [
    "def test_MaxPool2DLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 4\n",
    "  W = 4\n",
    "  pool_size = 2\n",
    "  stride = 2\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.MaxPooling2D(pool_size=pool_size, strides=stride, padding=\"valid\", data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test MaxPool2D 1')\n",
    "  B = 2\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  pool_size = 2\n",
    "  stride = 1  \n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.MaxPooling2D(pool_size=pool_size, strides=stride, padding=\"valid\", data_format='channels_first')\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = MaxPool2DLayer(pool_size=pool_size, stride=stride).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test MaxPool2D 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHRtvEIpVsYe"
   },
   "outputs": [],
   "source": [
    "test_MaxPool2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLtOD86byTQ-"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zruUuHDeZf-4"
   },
   "source": [
    "* (3 балла) Реализация слоя **активации** (поддерживаются **relu**, **sigmoid**, **softmax**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFytq6FOByQ9"
   },
   "outputs": [],
   "source": [
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation='relu'):\n",
    "      # Активация (поддерживаем 'relu', 'sigmoid', 'softmax')\n",
    "      self.name = 'Activation'\n",
    "      self.activation = activation\n",
    "    def forward(self, input_data):   \n",
    "      # На входе:\n",
    "      # четырехмерный тензор вида [batch, input_channels, height, width] для 'relu', 'sigmoid'\n",
    "      # или двухмерный тензор вида [batch, logits]\n",
    "      # SoftMax применяется по последней размерности\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RnOBuLTWcIf"
   },
   "outputs": [],
   "source": [
    "def test_ActivationLayer():\n",
    "  B = 1\n",
    "  C = 1\n",
    "  H = 4\n",
    "  W = 4\n",
    "  activation = 'relu'\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Activation(activation)\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = ActivationLayer(activation=activation).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 1')\n",
    "  B = 2\n",
    "  C = 2\n",
    "  H = 3\n",
    "  W = 3\n",
    "  activation = 'sigmoid'  \n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.Activation(activation)\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = ActivationLayer(activation=activation).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 2')\n",
    "  B = 3\n",
    "  C = 10\n",
    "  activation = 'softmax'\n",
    "  x = np.random.randn(B, C)\n",
    "  y = layers.Activation(activation)\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = ActivationLayer(activation=activation).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Activation 3')  \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3Bwcpw7X4_m"
   },
   "outputs": [],
   "source": [
    "test_ActivationLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YtW9jiayUdV"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dOJl776Z0t7"
   },
   "source": [
    "* (3 балла) Реализация слоя пакетной нормализации **BatchNorm** (как для режима train, так и для режима test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-bCGIE--8QH"
   },
   "outputs": [],
   "source": [
    "# Hint\n",
    "# Train mode:\n",
    "# out = (batch - mean(batch)) / sqrt(var(batch) + epsilon) * gamma + beta\n",
    "# moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)\n",
    "# moving_var = moving_var * momentum + var(batch) * (1 - momentum)\n",
    "# Test mode:\n",
    "# (batch - moving_mean) / sqrt(moving_var + epsilon) * gamma + beta\n",
    "\n",
    "class BatchNormLayer(Layer):\n",
    "    def __init__(self, momentum=0.99, epsilon=0.001, beta_init=None, gamma_init=None,\n",
    "                 moving_mean_init=None, moving_var_init=None,\n",
    "                 mode='train', input_channels=2):\n",
    "      # mode: 'train', 'test'\n",
    "      # Параметры gamma, beta, mean, var - все имеют размерность по количеству карт input_channels   \n",
    "      self.name = 'BatchNorm'\n",
    "      self.momentum = momentum\n",
    "      self.epsilon = epsilon\n",
    "      self.beta = beta_init\n",
    "      self.gamma = gamma_init\n",
    "      self.moving_mean = moving_mean_init\n",
    "      self.moving_var = moving_var_init\n",
    "      self.mode = mode\n",
    "      self.input_channels = input_channels\n",
    "    def forward(self, input_data):   \n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # 1) Нужно заполнить Numpy-тензор out (той же размерности, что и вход)\n",
    "      # 2) Нужно обновить moving_mean и moving_var в режиме 'train'\n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhZ6TK-RYfm-"
   },
   "outputs": [],
   "source": [
    "def test_BatchNormLayer():\n",
    "  B = 2\n",
    "  C = 2\n",
    "  H = 4\n",
    "  W = 4\n",
    "  beta_init = 0 * np.ones(C)\n",
    "  gamma_init = 1 * np.ones(C)\n",
    "  moving_mean_init = 0 * np.ones(C)\n",
    "  moving_var_init= 1 * np.ones(C)\n",
    "  momentum = 0.99\n",
    "  epsilon = 0.001\n",
    "  mode = 'train'\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.BatchNormalization(axis=1, momentum=momentum, epsilon=epsilon, trainable=True)\n",
    "  y_keras = y(x, training=True).numpy()\n",
    "  y.set_weights([gamma_init, beta_init, moving_mean_init, moving_var_init])\n",
    "  y_keras = y(x, training=True).numpy()\n",
    "  y_out_layer = BatchNormLayer(momentum=momentum, epsilon=epsilon, beta_init=beta_init, gamma_init=gamma_init,\n",
    "                 moving_mean_init=moving_mean_init, moving_var_init=moving_var_init,\n",
    "                 mode=mode, input_channels=C)\n",
    "  y_out = y_out_layer.forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test BatchNorm 1')\n",
    "  compare_tensors_array(y.get_weights(), \n",
    "                        [y_out_layer.gamma, y_out_layer.beta, y_out_layer.moving_mean, y_out_layer.moving_var],\n",
    "                        tol=0.00001, test_name='Test BatchNorm 1.1')\n",
    "  B = 2 \n",
    "  C = 2 \n",
    "  H = 4 \n",
    "  W = 4 \n",
    "  beta_init = 1 * np.ones(C)\n",
    "  gamma_init = 0 * np.ones(C)\n",
    "  moving_mean = 0 * np.ones(C)\n",
    "  moving_var = 1 * np.ones(C)\n",
    "  momentum = 0.99\n",
    "  epsilon = 0.001\n",
    "  mode = 'test'\n",
    "  x = np.random.randn(B, C, H, W)\n",
    "  y = layers.BatchNormalization(axis=1, momentum=momentum, epsilon=epsilon, trainable=False)\n",
    "  y_keras = y(x, training=False).numpy()\n",
    "  y.set_weights([gamma_init, beta_init, moving_mean, moving_var])\n",
    "  y_keras = y(x, training=False).numpy()\n",
    "  y_out_layer = BatchNormLayer(momentum=momentum, epsilon=epsilon, beta_init=beta_init, gamma_init=gamma_init,\n",
    "                 moving_mean_init=moving_mean_init, moving_var_init=moving_var_init,\n",
    "                 mode=mode, input_channels=C)\n",
    "  y_out = y_out_layer.forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test BatchNorm 2')  \n",
    "  compare_tensors_array(y.get_weights(), \n",
    "                        [y_out_layer.gamma, y_out_layer.beta, y_out_layer.moving_mean, y_out_layer.moving_var],\n",
    "                        tol=0.00001, test_name='Test BatchNorm 2.1')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZ2F0Xg1Yf94"
   },
   "outputs": [],
   "source": [
    "test_BatchNormLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJKt_4mCyV4r"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f_m9DaTaHio"
   },
   "source": [
    "* (1 балл) Реализация **полносвязного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ln22ERp8mC5"
   },
   "outputs": [],
   "source": [
    "class DenseLayer(Layer):\n",
    "    def __init__(self, input_dim, output_dim, W_init=None, b_init=None):\n",
    "      self.name = 'Dense'\n",
    "      self.input_dim = input_dim\n",
    "      self.output_dim = output_dim\n",
    "      self.W = W_init\n",
    "      self.b = b_init\n",
    "    def forward(self, input_data):\n",
    "      # На входе - двухмерный тензор вида [batch, input_channels]\n",
    "      # Работаем по второй размерности, по первой размерности НЕ преобразуем\n",
    "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ln9JIKL8YhZF"
   },
   "outputs": [],
   "source": [
    "def test_DenseLayer():\n",
    "  B = 1\n",
    "  C_IN = 10\n",
    "  C_OUT = 5\n",
    "  x = np.random.randn(B, C_IN)\n",
    "  W_init = np.random.randn(C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Dense(C_OUT, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([W_init, b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Dense 1')\n",
    "  B = 2\n",
    "  C_IN = 5\n",
    "  C_OUT = 10\n",
    "  x = np.random.randn(B, C_IN)\n",
    "  W_init = np.random.randn(C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Dense(C_OUT, use_bias=True, input_shape=(C_IN,))\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([W_init, b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = DenseLayer(C_IN, C_OUT, W_init=W_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Dense 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NA_KNjZYhec"
   },
   "outputs": [],
   "source": [
    "test_DenseLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "966wyQwryXun"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6A8OLysaS3Q"
   },
   "source": [
    "* (2 балла) Реализация **сверточного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quhEATTW9jyK"
   },
   "outputs": [],
   "source": [
    "class Conv2DLayer(Layer):\n",
    "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \n",
    "                 padding='same', stride=1, K_init=None, b_init=None):\n",
    "      # padding: 'same' или 'valid'\n",
    "      # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
    "      # Работаем с единообразным сдвигом, поэтому stride - одно число\n",
    "      # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
    "      self.name = 'Conv2D'\n",
    "      self.kernel_size = kernel_size\n",
    "      self.input_channels = input_channels\n",
    "      self.output_channels = output_channels\n",
    "      self.kernel = K_init\n",
    "      self.bias = b_init\n",
    "      self.padding = padding\n",
    "      self.stride = stride\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUA1PbOBYiH3"
   },
   "outputs": [],
   "source": [
    "def test_Conv2DLayer():\n",
    "  B = 1\n",
    "  C_IN = 1\n",
    "  C_OUT = 1\n",
    "  H = 10\n",
    "  W = 10\n",
    "  K = 3\n",
    "  S = 1\n",
    "  padding = 'same'\n",
    "  x = np.random.randn(B, C_IN, H, W)\n",
    "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Conv2D(C_OUT, K, strides=S, padding=padding, data_format='channels_first',\n",
    "    dilation_rate=1, groups=1, activation=None, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([K_init, b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = Conv2DLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2D 1')\n",
    "  B = 2\n",
    "  C_IN = 3\n",
    "  C_OUT = 5\n",
    "  H = 9\n",
    "  W = 9\n",
    "  K = 3\n",
    "  S = 2\n",
    "  padding = 'valid'\n",
    "  x = np.random.randn(B, C_IN, H, W)\n",
    "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Conv2D(C_OUT, K, strides=S, padding=padding, data_format='channels_first',\n",
    "    dilation_rate=1, groups=1, activation=None, use_bias=True, input_shape=(C_IN, H, W))\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([K_init, b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = Conv2DLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2D 1')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZI5iUu4YiOD"
   },
   "outputs": [],
   "source": [
    "test_Conv2DLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91-bDvSvyY2e"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hPqOr5zad6H"
   },
   "source": [
    "* (2 балла) Реализация **транспонированного сверточного** слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97D7QOwm-ER1"
   },
   "outputs": [],
   "source": [
    "class Conv2DTrLayer(Layer):\n",
    "    def __init__(self, kernel_size=3, input_channels=2, output_channels=3, \n",
    "                 padding=0, stride=1, K_init=None, b_init=None):      \n",
    "      # padding: число (сколько отрезать от модифицированной входной карты)\n",
    "      # Работаем с квадратными ядрами, поэтому kernel_size - одно число\n",
    "      # stride - одно число (коэффициент расширения)\n",
    "      # Фильтр размерности [kernel_size, kernel_size, input_channels, output_channels]\n",
    "      self.name = 'Conv2DTr'\n",
    "      self.kernel_size = kernel_size\n",
    "      self.input_channels = input_channels\n",
    "      self.output_channels = output_channels\n",
    "      self.kernel = K_init\n",
    "      self.bias = b_init\n",
    "      self.padding = padding\n",
    "      self.stride = stride\n",
    "    def forward(self, input_data):\n",
    "      # На входе - четырехмерный тензор вида [batch, input_channels, height, width]\n",
    "      # Вначале нужно проверить на согласование размерностей входных данных и ядра!\n",
    "      # Нужно заполнить Numpy-тензор out \n",
    "      out = np.empty([])\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueU3lS9-Yi8t"
   },
   "outputs": [],
   "source": [
    "def adjust_kernel(K):\n",
    "  K_new = K.copy()[::-1, ::-1, :, :]\n",
    "  K_new = np.transpose(K_new, (0, 1, 3, 2))\n",
    "  return K_new\n",
    "\n",
    "def test_Conv2DTrLayer():\n",
    "  B = 1\n",
    "  C_IN = 1\n",
    "  C_OUT = 1\n",
    "  H = 3\n",
    "  W = 3\n",
    "  K = 3\n",
    "  S = 2\n",
    "  padding = 0\n",
    "  x = np.random.randn(B, C_IN, H, W)\n",
    "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Conv2DTranspose(C_OUT, K, strides=S, padding=\"valid\", output_padding=None, \n",
    "                    data_format='channels_first', dilation_rate=1, groups=1, \n",
    "                    activation=None, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([adjust_kernel(K_init), b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = Conv2DTrLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2DTr 1')\n",
    "  B = 4\n",
    "  C_IN = 2\n",
    "  C_OUT = 3\n",
    "  H = 3\n",
    "  W = 3\n",
    "  K = 3\n",
    "  S = 2\n",
    "  padding = 0\n",
    "  x = np.random.randn(B, C_IN, H, W)\n",
    "  K_init = np.random.randn(K, K, C_IN, C_OUT)\n",
    "  b_init = np.random.randn(C_OUT)\n",
    "  y = layers.Conv2DTranspose(C_OUT, K, strides=S, padding=\"valid\", output_padding=None, \n",
    "                    data_format='channels_first', dilation_rate=1, groups=1, \n",
    "                    activation=None, use_bias=True)\n",
    "  y_keras = y(x).numpy()\n",
    "  y.set_weights([adjust_kernel(K_init), b_init])\n",
    "  y_keras = y(x).numpy()\n",
    "  y_out = Conv2DTrLayer(kernel_size=K, input_channels=C_IN, output_channels=C_OUT, \n",
    "                 padding=padding, stride=S, K_init=K_init, b_init=b_init).forward(x)\n",
    "  compare_tensors(y_keras, y_out, tol=0.001, test_name='Test Conv2DTr 2')\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rW2REQR3-6dd"
   },
   "outputs": [],
   "source": [
    "test_Conv2DTrLayer()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Practice01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
